{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum, Value, and Size Premiums\n",
    "## Financial Technology - AI Trading Assignment\n",
    "\n",
    "This notebook tests whether classic asset pricing factors (market beta, size, value, momentum) show up in a large sample of U.S. stocks using firm-level regressions on merged CRSP-Compustat monthly data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 1: Load and Explore the Data\n",
    "Load the data. Report the number of observations, the date range, and the number of unique firms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA NOTE:\n",
    "# Parquet file is stored locally and NOT tracked in GitHub\n",
    "# Update DATA_PATH as needed\n",
    "\n",
    "DATA_PATH = r\"D:\\AI Trading - Fin Tech\\stock_data_filtered.parquet\"\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "\n",
    "# Ensure date column is datetime\n",
    "df['MthCalDt'] = pd.to_datetime(df['MthCalDt'])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Number of observations:  {len(df):,}\")\n",
    "print(f\"Number of columns:       {df.shape[1]}\")\n",
    "print(f\"Number of unique firms:  {df['PERMNO'].nunique():,}\")\n",
    "print(f\"Date range:              {df['MthCalDt'].min().strftime('%Y-%m')} to {df['MthCalDt'].max().strftime('%Y-%m')}\")\n",
    "print(f\"Number of unique months: {df['MthCalDt'].nunique()}\")\n",
    "print(\"\\nReturn (MthRet) summary statistics:\")\n",
    "print(df['MthRet'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 2: Define the Variables\n",
    "\n",
    "Construct the following factor characteristics for each firm-month:\n",
    "- **(a) Market Beta** - rolling 60-month regression of firm returns on equal-weighted market return\n",
    "- **(b) Size** - log of market capitalization (price x shares outstanding)\n",
    "- **(c) Value (Book-to-Market)** - book equity / market equity\n",
    "- **(d) Momentum** - cumulative return over months t-12 to t-2 (skip most recent month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data for rolling calculations\n",
    "df = df.sort_values(['PERMNO', 'MthCalDt']).reset_index(drop=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# (b) SIZE: log of market capitalization\n",
    "# Market cap = share price (prcc_c) * shares outstanding (csho)\n",
    "# prcc_c is calendar-year price; csho is in millions\n",
    "# ------------------------------------------------------------------\n",
    "df['MktCap'] = df['prcc_c'].abs() * df['csho']  # abs() handles negative prices (bid-ask)\n",
    "df['Size'] = np.log(df['MktCap'].replace(0, np.nan))\n",
    "\n",
    "print(\"Size (log market cap) summary:\")\n",
    "print(df['Size'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# (c) VALUE: Book-to-Market ratio\n",
    "# Book equity = stockholders' equity (seq) + deferred taxes (txdb, 0 if missing)\n",
    "#              - preferred stock (pstkl or pstk, 0 if missing)\n",
    "# Market equity = MktCap\n",
    "# ------------------------------------------------------------------\n",
    "df['BookEquity'] = df['seq'].fillna(df['ceq'] + df['pstk'].fillna(0))\n",
    "df['BookEquity'] = df['BookEquity'] + df['txdb'].fillna(0) - df['pstkl'].fillna(df['pstk'].fillna(0))\n",
    "\n",
    "df['BM'] = df['BookEquity'] / df['MktCap'].replace(0, np.nan)\n",
    "\n",
    "# Winsorize B/M at 1st and 99th percentiles to handle outliers\n",
    "bm_lower = df['BM'].quantile(0.01)\n",
    "bm_upper = df['BM'].quantile(0.99)\n",
    "df['BM'] = df['BM'].clip(lower=bm_lower, upper=bm_upper)\n",
    "\n",
    "print(\"Book-to-Market ratio summary:\")\n",
    "print(df['BM'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# (a) MARKET BETA: rolling 60-month regression on equal-weighted market return\n",
    "# First compute the equal-weighted market return each month\n",
    "# ------------------------------------------------------------------\n",
    "mkt_ret = df.groupby('MthCalDt')['MthRet'].mean().rename('MktRet')\n",
    "df = df.merge(mkt_ret, on='MthCalDt', how='left')\n",
    "\n",
    "def rolling_beta(group, window=60, min_periods=24):\n",
    "    \"\"\"Compute rolling beta for a single firm using vectorized rolling covariance.\"\"\"\n",
    "    ret = group['MthRet']\n",
    "    mkt = group['MktRet']\n",
    "    cov = ret.rolling(window=window, min_periods=min_periods).cov(mkt)\n",
    "    var = mkt.rolling(window=window, min_periods=min_periods).var()\n",
    "    return cov / var\n",
    "\n",
    "print(\"Computing rolling betas (this may take a few minutes)...\")\n",
    "df['Beta'] = df.groupby('PERMNO', group_keys=False).apply(rolling_beta)\n",
    "\n",
    "# Winsorize beta at 1st and 99th percentiles\n",
    "beta_lower = df['Beta'].quantile(0.01)\n",
    "beta_upper = df['Beta'].quantile(0.99)\n",
    "df['Beta'] = df['Beta'].clip(lower=beta_lower, upper=beta_upper)\n",
    "\n",
    "print(\"Market Beta summary:\")\n",
    "print(df['Beta'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# (d) MOMENTUM: cumulative return from t-12 to t-2\n",
    "# Skip the most recent month (t-1) to avoid short-term reversal\n",
    "# ------------------------------------------------------------------\n",
    "def compute_momentum(group):\n",
    "    \"\"\"Momentum = cumulative return from t-12 to t-2.\"\"\"\n",
    "    ret = group['MthRet']\n",
    "    # Cumulative return over 11 months (t-12 to t-2): product of (1+r) then subtract 1\n",
    "    cum_12 = (1 + ret).rolling(window=11, min_periods=6).apply(np.prod, raw=True) - 1\n",
    "    # Shift by 1 to skip the most recent month (use returns from t-12 to t-2, not t-1)\n",
    "    return cum_12.shift(1)\n",
    "\n",
    "print(\"Computing momentum...\")\n",
    "df['Momentum'] = df.groupby('PERMNO', group_keys=False).apply(compute_momentum)\n",
    "\n",
    "# Winsorize momentum at 1st and 99th percentiles\n",
    "mom_lower = df['Momentum'].quantile(0.01)\n",
    "mom_upper = df['Momentum'].quantile(0.99)\n",
    "df['Momentum'] = df['Momentum'].clip(lower=mom_lower, upper=mom_upper)\n",
    "\n",
    "print(\"Momentum summary:\")\n",
    "print(df['Momentum'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Create next-month return (the dependent variable)\n",
    "# ------------------------------------------------------------------\n",
    "df['NextRet'] = df.groupby('PERMNO')['MthRet'].shift(-1)\n",
    "\n",
    "print(\"Next-month return summary:\")\n",
    "print(df['NextRet'].describe())\n",
    "\n",
    "# Summary of factor coverage\n",
    "factors = ['Beta', 'Size', 'BM', 'Momentum', 'NextRet']\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FACTOR VARIABLE COVERAGE\")\n",
    "print(\"=\"*60)\n",
    "for col in factors:\n",
    "    n_valid = df[col].notna().sum()\n",
    "    pct = 100 * n_valid / len(df)\n",
    "    print(f\"{col:12s}: {n_valid:>10,} non-missing ({pct:.1f}%)\")\n",
    "\n",
    "# Create regression-ready sample\n",
    "reg_df = df.dropna(subset=factors).copy()\n",
    "print(f\"\\nRegression sample size: {len(reg_df):,} observations\")\n",
    "print(f\"Unique firms in sample: {reg_df['PERMNO'].nunique():,}\")\n",
    "print(f\"Date range: {reg_df['MthCalDt'].min().strftime('%Y-%m')} to {reg_df['MthCalDt'].max().strftime('%Y-%m')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 4: Single-Factor Model\n",
    "\n",
    "Run a pooled OLS regression of next-month firm returns on market beta only, with standard errors clustered by firm and month (double-clustered) to correct for correlation in the error term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Pooled OLS: NextRet ~ Beta\n",
    "# Double-clustered standard errors (by firm and by month)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Prepare data\n",
    "X_beta = sm.add_constant(reg_df['Beta'])\n",
    "y = reg_df['NextRet']\n",
    "\n",
    "# Fit OLS\n",
    "model_q4 = OLS(y, X_beta).fit(\n",
    "    cov_type='cluster',\n",
    "    cov_kwds={'groups': reg_df[['PERMNO', 'MthCalDt']].values}\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"QUESTION 4: Single-Factor Model (Beta Only)\")\n",
    "print(\"Dependent variable: Next-month return\")\n",
    "print(\"Standard errors: Double-clustered by firm and month\")\n",
    "print(\"=\"*60)\n",
    "print(model_q4.summary().tables[1])\n",
    "print(f\"\\nN = {int(model_q4.nobs):,}\")\n",
    "print(f\"R-squared = {model_q4.rsquared:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 5: Full Factor Model\n",
    "\n",
    "Run the full model with all four factors: market beta, size, value, and momentum. Use pooled OLS with double-clustered standard errors.\n",
    "\n",
    "**(a)** Report coefficient estimates and t-statistics.  \n",
    "**(b)** Interpret the signs of the coefficients.  \n",
    "**(c)** Compare with Jegadeesh & Titman (1993) and Fama & French (2015)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Pooled OLS: NextRet ~ Beta + Size + BM + Momentum\n",
    "# Double-clustered standard errors (by firm and by month)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "factor_cols = ['Beta', 'Size', 'BM', 'Momentum']\n",
    "X_full = sm.add_constant(reg_df[factor_cols])\n",
    "y = reg_df['NextRet']\n",
    "\n",
    "model_q5 = OLS(y, X_full).fit(\n",
    "    cov_type='cluster',\n",
    "    cov_kwds={'groups': reg_df[['PERMNO', 'MthCalDt']].values}\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"QUESTION 5: Full Factor Model\")\n",
    "print(\"Dependent variable: Next-month return\")\n",
    "print(\"Standard errors: Double-clustered by firm and month\")\n",
    "print(\"=\"*60)\n",
    "print(model_q5.summary().tables[1])\n",
    "print(f\"\\nN = {int(model_q5.nobs):,}\")\n",
    "print(f\"R-squared = {model_q5.rsquared:.6f}\")\n",
    "print(f\"Adj. R-squared = {model_q5.rsquared_adj:.6f}\")\n",
    "\n",
    "# Detailed results table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"(a) Coefficient Estimates and T-Statistics\")\n",
    "print(\"=\"*60)\n",
    "results_table = pd.DataFrame({\n",
    "    'Coefficient': model_q5.params,\n",
    "    'Std Error': model_q5.bse,\n",
    "    't-statistic': model_q5.tvalues,\n",
    "    'p-value': model_q5.pvalues\n",
    "})\n",
    "print(results_table.to_string(float_format='{:.6f}'.format))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"(b) Interpretation of Coefficient Signs\")\n",
    "print(\"=\"*60)\n",
    "for var in factor_cols:\n",
    "    coef = model_q5.params[var]\n",
    "    pval = model_q5.pvalues[var]\n",
    "    sig = \"***\" if pval < 0.01 else \"**\" if pval < 0.05 else \"*\" if pval < 0.1 else \"\"\n",
    "    direction = \"positive\" if coef > 0 else \"negative\"\n",
    "    print(f\"  {var:12s}: {coef:+.6f} ({direction}) {sig}\")\n",
    "\n",
    "print(\"\\n(c) Consistency with literature:\")\n",
    "print(\"  - Jegadeesh & Titman (1993): Momentum should have a POSITIVE coefficient\")\n",
    "print(\"    (winners continue winning, losers continue losing)\")\n",
    "print(\"  - Fama & French (2015): Size should be NEGATIVE (small firms earn higher returns),\")\n",
    "print(\"    Value (B/M) should be POSITIVE (high B/M firms earn higher returns)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 6: Are the Effects Linear?\n",
    "\n",
    "Add a quadratic term for each of the four factors. Test whether any are statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Add quadratic terms: Beta^2, Size^2, BM^2, Momentum^2\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "for col in factor_cols:\n",
    "    reg_df[col + '_sq'] = reg_df[col] ** 2\n",
    "\n",
    "quad_cols = factor_cols + [c + '_sq' for c in factor_cols]\n",
    "X_quad = sm.add_constant(reg_df[quad_cols])\n",
    "y = reg_df['NextRet']\n",
    "\n",
    "model_q6 = OLS(y, X_quad).fit(\n",
    "    cov_type='cluster',\n",
    "    cov_kwds={'groups': reg_df[['PERMNO', 'MthCalDt']].values}\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"QUESTION 6: Model with Quadratic Terms\")\n",
    "print(\"Dependent variable: Next-month return\")\n",
    "print(\"Standard errors: Double-clustered by firm and month\")\n",
    "print(\"=\"*60)\n",
    "print(model_q6.summary().tables[1])\n",
    "print(f\"\\nN = {int(model_q6.nobs):,}\")\n",
    "print(f\"R-squared = {model_q6.rsquared:.6f}\")\n",
    "\n",
    "# Highlight significant quadratic terms\n",
    "print(\"\\nQuadratic term significance:\")\n",
    "for col in factor_cols:\n",
    "    sq_col = col + '_sq'\n",
    "    coef = model_q6.params[sq_col]\n",
    "    pval = model_q6.pvalues[sq_col]\n",
    "    sig = \"***\" if pval < 0.01 else \"**\" if pval < 0.05 else \"*\" if pval < 0.1 else \"not significant\"\n",
    "    print(f\"  {sq_col:15s}: coef={coef:+.6f}, p-value={pval:.4f}  [{sig}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 7: Subsample Analysis\n",
    "\n",
    "Re-run the full linear model on different subsamples to see if premiums have changed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Split into roughly equal subperiods\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "reg_df['Year'] = reg_df['MthCalDt'].dt.year\n",
    "min_year = reg_df['Year'].min()\n",
    "max_year = reg_df['Year'].max()\n",
    "mid_year = (min_year + max_year) // 2\n",
    "\n",
    "# Define subperiods\n",
    "third = (max_year - min_year) // 3\n",
    "periods = {\n",
    "    f'Early ({min_year}-{min_year + third})': (min_year, min_year + third),\n",
    "    f'Middle ({min_year + third + 1}-{min_year + 2*third})': (min_year + third + 1, min_year + 2*third),\n",
    "    f'Late ({min_year + 2*third + 1}-{max_year})': (min_year + 2*third + 1, max_year),\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"QUESTION 7: Subsample Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "subsample_results = {}\n",
    "\n",
    "for period_name, (start, end) in periods.items():\n",
    "    sub = reg_df[(reg_df['Year'] >= start) & (reg_df['Year'] <= end)]\n",
    "    if len(sub) < 100:\n",
    "        continue\n",
    "    \n",
    "    X_sub = sm.add_constant(sub[factor_cols])\n",
    "    y_sub = sub['NextRet']\n",
    "    \n",
    "    model_sub = OLS(y_sub, X_sub).fit(\n",
    "        cov_type='cluster',\n",
    "        cov_kwds={'groups': sub[['PERMNO', 'MthCalDt']].values}\n",
    "    )\n",
    "    \n",
    "    subsample_results[period_name] = {\n",
    "        'N': int(model_sub.nobs),\n",
    "        'coefs': model_sub.params[factor_cols],\n",
    "        'tvals': model_sub.tvalues[factor_cols],\n",
    "        'pvals': model_sub.pvalues[factor_cols],\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n--- {period_name} (N={int(model_sub.nobs):,}) ---\")\n",
    "    for var in factor_cols:\n",
    "        coef = model_sub.params[var]\n",
    "        tval = model_sub.tvalues[var]\n",
    "        pval = model_sub.pvalues[var]\n",
    "        sig = \"***\" if pval < 0.01 else \"**\" if pval < 0.05 else \"*\" if pval < 0.1 else \"\"\n",
    "        print(f\"    {var:12s}: coef={coef:+.6f}, t={tval:+.3f} {sig}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Visualize how factor premiums evolve over time\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Compare coefficients across subperiods\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Factor Premiums Across Subperiods', fontsize=14, fontweight='bold')\n",
    "\n",
    "for idx, var in enumerate(factor_cols):\n",
    "    ax = axes[idx // 2][idx % 2]\n",
    "    period_names = list(subsample_results.keys())\n",
    "    coefs = [subsample_results[p]['coefs'][var] for p in period_names]\n",
    "    tvals = [subsample_results[p]['tvals'][var] for p in period_names]\n",
    "    \n",
    "    colors = ['green' if abs(t) > 1.96 else 'red' for t in tvals]\n",
    "    bars = ax.bar(range(len(period_names)), coefs, color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax.set_title(f'{var} Premium', fontweight='bold')\n",
    "    ax.set_ylabel('Coefficient')\n",
    "    ax.set_xticks(range(len(period_names)))\n",
    "    ax.set_xticklabels([p.split('(')[0].strip() for p in period_names], fontsize=9)\n",
    "    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    # Add t-stat labels\n",
    "    for i, (c, t) in enumerate(zip(coefs, tvals)):\n",
    "        ax.text(i, c, f't={t:.2f}', ha='center', va='bottom' if c > 0 else 'top', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('subsample_premiums.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Green = significant at 5%; Red = not significant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 8: Out-of-Sample Backtesting\n",
    "\n",
    "Estimate the full linear model on a training set, predict returns on a test set, and form long-short portfolios. Report average return and Sharpe ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Train/Test split: first 70% of months for training, last 30% for testing\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "unique_months = sorted(reg_df['MthCalDt'].unique())\n",
    "split_idx = int(len(unique_months) * 0.7)\n",
    "train_end = unique_months[split_idx]\n",
    "\n",
    "train_df = reg_df[reg_df['MthCalDt'] <= train_end].copy()\n",
    "test_df = reg_df[reg_df['MthCalDt'] > train_end].copy()\n",
    "\n",
    "print(f\"Training period: {train_df['MthCalDt'].min().strftime('%Y-%m')} to {train_df['MthCalDt'].max().strftime('%Y-%m')}\")\n",
    "print(f\"Training observations: {len(train_df):,}\")\n",
    "print(f\"\\nTest period: {test_df['MthCalDt'].min().strftime('%Y-%m')} to {test_df['MthCalDt'].max().strftime('%Y-%m')}\")\n",
    "print(f\"Test observations: {len(test_df):,}\")\n",
    "\n",
    "# Estimate model on training data\n",
    "X_train = sm.add_constant(train_df[factor_cols])\n",
    "y_train = train_df['NextRet']\n",
    "model_train = OLS(y_train, X_train).fit()\n",
    "\n",
    "print(\"\\nTraining model coefficients:\")\n",
    "print(model_train.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Predict returns and form long-short portfolios in the test period\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Predict expected returns\n",
    "X_test = sm.add_constant(test_df[factor_cols])\n",
    "test_df['PredRet'] = model_train.predict(X_test)\n",
    "\n",
    "# Each month: go long top quintile, short bottom quintile\n",
    "portfolio_returns = []\n",
    "\n",
    "for month, group in test_df.groupby('MthCalDt'):\n",
    "    if len(group) < 20:\n",
    "        continue\n",
    "    \n",
    "    # Rank stocks by predicted return\n",
    "    group = group.copy()\n",
    "    group['quintile'] = pd.qcut(group['PredRet'], 5, labels=False, duplicates='drop')\n",
    "    \n",
    "    # Long top quintile (4), short bottom quintile (0)\n",
    "    long_ret = group[group['quintile'] == 4]['NextRet'].mean()\n",
    "    short_ret = group[group['quintile'] == 0]['NextRet'].mean()\n",
    "    ls_ret = long_ret - short_ret\n",
    "    \n",
    "    portfolio_returns.append({\n",
    "        'Month': month,\n",
    "        'Long': long_ret,\n",
    "        'Short': short_ret,\n",
    "        'LongShort': ls_ret,\n",
    "        'N_stocks': len(group)\n",
    "    })\n",
    "\n",
    "port_df = pd.DataFrame(portfolio_returns)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"QUESTION 8: Out-of-Sample Backtesting Results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Monthly statistics\n",
    "avg_ls = port_df['LongShort'].mean()\n",
    "std_ls = port_df['LongShort'].std()\n",
    "sharpe_monthly = avg_ls / std_ls if std_ls > 0 else 0\n",
    "sharpe_annual = sharpe_monthly * np.sqrt(12)\n",
    "\n",
    "print(f\"\\nLong-Short Portfolio (monthly):\")\n",
    "print(f\"  Average return:     {avg_ls:.4f} ({avg_ls*100:.2f}%)\")\n",
    "print(f\"  Std deviation:      {std_ls:.4f}\")\n",
    "print(f\"  Monthly Sharpe:     {sharpe_monthly:.4f}\")\n",
    "print(f\"  Annualized Sharpe:  {sharpe_annual:.4f}\")\n",
    "print(f\"  Number of months:   {len(port_df)}\")\n",
    "\n",
    "# T-test: is average return significantly different from zero?\n",
    "t_stat = avg_ls / (std_ls / np.sqrt(len(port_df)))\n",
    "print(f\"  t-statistic:        {t_stat:.3f}\")\n",
    "\n",
    "print(f\"\\nLong portfolio avg return:   {port_df['Long'].mean():.4f} ({port_df['Long'].mean()*100:.2f}%)\")\n",
    "print(f\"Short portfolio avg return:  {port_df['Short'].mean():.4f} ({port_df['Short'].mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Plot cumulative returns\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "port_df = port_df.sort_values('Month')\n",
    "port_df['CumLong'] = (1 + port_df['Long']).cumprod()\n",
    "port_df['CumShort'] = (1 + port_df['Short']).cumprod()\n",
    "port_df['CumLS'] = (1 + port_df['LongShort']).cumprod()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Cumulative returns\n",
    "ax1.plot(port_df['Month'], port_df['CumLS'], 'b-', linewidth=1.5, label='Long-Short')\n",
    "ax1.plot(port_df['Month'], port_df['CumLong'], 'g--', linewidth=1, alpha=0.7, label='Long (Top Quintile)')\n",
    "ax1.plot(port_df['Month'], port_df['CumShort'], 'r--', linewidth=1, alpha=0.7, label='Short (Bottom Quintile)')\n",
    "ax1.axhline(y=1, color='black', linestyle='-', linewidth=0.5)\n",
    "ax1.set_title('Cumulative Returns: Out-of-Sample Backtest', fontweight='bold')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Cumulative Return ($1 invested)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly L/S returns distribution\n",
    "ax2.hist(port_df['LongShort'], bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "ax2.axvline(x=avg_ls, color='red', linestyle='--', linewidth=2, label=f'Mean = {avg_ls:.4f}')\n",
    "ax2.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax2.set_title('Distribution of Monthly Long-Short Returns', fontweight='bold')\n",
    "ax2.set_xlabel('Monthly Return')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('backtest_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 9: Factor Farming\n",
    "\n",
    "Select 20 plausible accounting variables, normalize them cross-sectionally, test in-sample and out-of-sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# (a) Select 20 plausible accounting variables as candidate factors\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# These are economically motivated variables from the Compustat data:\n",
    "candidate_factors = {\n",
    "    'gp':       'Gross Profit (profitability)',\n",
    "    'ebitda':   'EBITDA (operating profitability)',\n",
    "    'ni':       'Net Income (bottom-line profitability)',\n",
    "    'oibdp':    'Operating Income Before Depreciation',\n",
    "    'sale':     'Total Sales (revenue)',\n",
    "    'at':       'Total Assets (firm size alt.)',\n",
    "    'capx':     'Capital Expenditures (investment)',\n",
    "    'dltt':     'Long-Term Debt (leverage)',\n",
    "    'che':      'Cash & Short-Term Investments (liquidity)',\n",
    "    'invt':     'Total Inventory',\n",
    "    'dp':       'Depreciation & Amortization',\n",
    "    'xsga':     'SG&A Expense (overhead)',\n",
    "    'xint':     'Interest Expense (debt burden)',\n",
    "    'txt':      'Total Income Taxes',\n",
    "    'dvc':      'Dividends - Common (payout)',\n",
    "    'sstk':     'Sale of Common Stock (issuance)',\n",
    "    'prstkc':   'Purchase of Common Stock (buybacks)',\n",
    "    'emp':      'Number of Employees',\n",
    "    'ppent':    'Net PP&E (tangibility)',\n",
    "    'rect':     'Receivables - Total',\n",
    "}\n",
    "\n",
    "# Filter to variables that actually exist in our data\n",
    "available_factors = [v for v in candidate_factors.keys() if v in df.columns]\n",
    "print(f\"Selected {len(available_factors)} candidate accounting variables:\")\n",
    "for i, var in enumerate(available_factors, 1):\n",
    "    pct_valid = 100 * df[var].notna().sum() / len(df)\n",
    "    print(f\"  {i:2d}. {var:10s} - {candidate_factors[var]} ({pct_valid:.1f}% non-missing)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Normalize each candidate factor cross-sectionally (within each month)\n",
    "# Scale by total assets to make variables comparable across firms\n",
    "# Then rank-normalize to ensure uniform distribution\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Create normalized versions: scale by total assets, then cross-sectional z-score\n",
    "for var in available_factors:\n",
    "    col_name = var + '_norm'\n",
    "    \n",
    "    # Scale by total assets (except 'at' itself and 'emp')\n",
    "    if var not in ['at', 'emp']:\n",
    "        raw = df[var] / df['at'].replace(0, np.nan)\n",
    "    else:\n",
    "        raw = df[var].copy()\n",
    "    \n",
    "    # Cross-sectional z-score normalization (within each month)\n",
    "    df[col_name] = raw.groupby(df['MthCalDt']).transform(\n",
    "        lambda x: (x - x.mean()) / x.std() if x.std() > 0 else 0\n",
    "    )\n",
    "    \n",
    "    # Winsorize at 1st/99th percentiles\n",
    "    lower = df[col_name].quantile(0.01)\n",
    "    upper = df[col_name].quantile(0.99)\n",
    "    df[col_name] = df[col_name].clip(lower=lower, upper=upper)\n",
    "\n",
    "# Recompute NextRet since df may have changed\n",
    "norm_cols = [v + '_norm' for v in available_factors]\n",
    "\n",
    "print(f\"Normalized {len(norm_cols)} variables cross-sectionally.\")\n",
    "print(\"\\nSample statistics of normalized variables:\")\n",
    "print(df[norm_cols].describe().T[['mean', 'std', 'min', 'max']].to_string(float_format='{:.3f}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# (b) Split into training and test periods\n",
    "# Run single-factor regressions for each candidate\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Ensure NextRet is defined\n",
    "if 'NextRet' not in df.columns:\n",
    "    df['NextRet'] = df.groupby('PERMNO')['MthRet'].shift(-1)\n",
    "\n",
    "# Use same 70/30 split\n",
    "all_months = sorted(df['MthCalDt'].unique())\n",
    "split_point = all_months[int(len(all_months) * 0.7)]\n",
    "\n",
    "farm_train = df[df['MthCalDt'] <= split_point].copy()\n",
    "farm_test = df[df['MthCalDt'] > split_point].copy()\n",
    "\n",
    "print(f\"Training period: {farm_train['MthCalDt'].min().strftime('%Y-%m')} to {farm_train['MthCalDt'].max().strftime('%Y-%m')}\")\n",
    "print(f\"Test period:     {farm_test['MthCalDt'].min().strftime('%Y-%m')} to {farm_test['MthCalDt'].max().strftime('%Y-%m')}\")\n",
    "\n",
    "# Run single-factor regressions\n",
    "results_insample = []\n",
    "results_oos = []\n",
    "\n",
    "for var in available_factors:\n",
    "    norm_var = var + '_norm'\n",
    "    \n",
    "    # --- In-sample regression ---\n",
    "    train_sub = farm_train.dropna(subset=[norm_var, 'NextRet'])\n",
    "    if len(train_sub) < 100:\n",
    "        continue\n",
    "    \n",
    "    X_is = sm.add_constant(train_sub[norm_var])\n",
    "    y_is = train_sub['NextRet']\n",
    "    model_is = OLS(y_is, X_is).fit(\n",
    "        cov_type='cluster',\n",
    "        cov_kwds={'groups': train_sub[['PERMNO', 'MthCalDt']].values}\n",
    "    )\n",
    "    \n",
    "    # --- Out-of-sample regression ---\n",
    "    test_sub = farm_test.dropna(subset=[norm_var, 'NextRet'])\n",
    "    if len(test_sub) < 100:\n",
    "        results_insample.append({\n",
    "            'Variable': var,\n",
    "            'Description': candidate_factors[var],\n",
    "            'IS_coef': model_is.params[norm_var],\n",
    "            'IS_tstat': model_is.tvalues[norm_var],\n",
    "            'IS_pval': model_is.pvalues[norm_var],\n",
    "            'IS_significant': model_is.pvalues[norm_var] < 0.05,\n",
    "            'OOS_coef': np.nan,\n",
    "            'OOS_tstat': np.nan,\n",
    "            'OOS_pval': np.nan,\n",
    "            'OOS_significant': False,\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    X_oos = sm.add_constant(test_sub[norm_var])\n",
    "    y_oos = test_sub['NextRet']\n",
    "    model_oos = OLS(y_oos, X_oos).fit(\n",
    "        cov_type='cluster',\n",
    "        cov_kwds={'groups': test_sub[['PERMNO', 'MthCalDt']].values}\n",
    "    )\n",
    "    \n",
    "    # Same sign and significant OOS?\n",
    "    same_sign = np.sign(model_is.params[norm_var]) == np.sign(model_oos.params[norm_var])\n",
    "    \n",
    "    results_insample.append({\n",
    "        'Variable': var,\n",
    "        'Description': candidate_factors[var],\n",
    "        'IS_coef': model_is.params[norm_var],\n",
    "        'IS_tstat': model_is.tvalues[norm_var],\n",
    "        'IS_pval': model_is.pvalues[norm_var],\n",
    "        'IS_significant': model_is.pvalues[norm_var] < 0.05,\n",
    "        'OOS_coef': model_oos.params[norm_var],\n",
    "        'OOS_tstat': model_oos.tvalues[norm_var],\n",
    "        'OOS_pval': model_oos.pvalues[norm_var],\n",
    "        'OOS_significant': model_oos.pvalues[norm_var] < 0.05,\n",
    "        'Same_sign': same_sign,\n",
    "        'Survives_OOS': model_is.pvalues[norm_var] < 0.05 and model_oos.pvalues[norm_var] < 0.05 and same_sign,\n",
    "    })\n",
    "\n",
    "results_ff = pd.DataFrame(results_insample)\n",
    "print(\"\\nFactor farming results computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# (c) Report results\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"QUESTION 9: Factor Farming Results\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display full results table\n",
    "display_cols = ['Variable', 'Description', 'IS_coef', 'IS_tstat', 'IS_significant', \n",
    "                'OOS_coef', 'OOS_tstat', 'OOS_significant']\n",
    "if 'Survives_OOS' in results_ff.columns:\n",
    "    display_cols.append('Survives_OOS')\n",
    "\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(results_ff[display_cols].to_string(index=False, float_format='{:.4f}'.format))\n",
    "\n",
    "# Summary statistics\n",
    "n_total = len(results_ff)\n",
    "n_sig_is = results_ff['IS_significant'].sum()\n",
    "n_sig_oos = results_ff['OOS_significant'].sum() if 'OOS_significant' in results_ff.columns else 0\n",
    "n_survives = results_ff['Survives_OOS'].sum() if 'Survives_OOS' in results_ff.columns else 0\n",
    "survival_rate = n_survives / n_sig_is * 100 if n_sig_is > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total candidate factors tested:            {n_total}\")\n",
    "print(f\"Significant in-sample (p < 0.05):          {n_sig_is} ({100*n_sig_is/n_total:.0f}%)\")\n",
    "print(f\"Significant out-of-sample (p < 0.05):      {n_sig_oos}\")\n",
    "print(f\"Survive OOS (sig + same sign):             {n_survives}\")\n",
    "print(f\"Survival rate (OOS survivors / IS sig):     {survival_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# (d) Visualization and discussion\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Plot: In-sample vs Out-of-sample t-statistics\n",
    "valid = results_ff.dropna(subset=['IS_tstat', 'OOS_tstat'])\n",
    "colors = ['green' if s else 'red' for s in valid.get('Survives_OOS', [False]*len(valid))]\n",
    "ax1.scatter(valid['IS_tstat'], valid['OOS_tstat'], c=colors, s=80, alpha=0.7, edgecolors='black')\n",
    "ax1.axhline(y=1.96, color='gray', linestyle='--', alpha=0.5, label='t=1.96')\n",
    "ax1.axhline(y=-1.96, color='gray', linestyle='--', alpha=0.5)\n",
    "ax1.axvline(x=1.96, color='gray', linestyle='--', alpha=0.5)\n",
    "ax1.axvline(x=-1.96, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Label each point\n",
    "for _, row in valid.iterrows():\n",
    "    ax1.annotate(row['Variable'], (row['IS_tstat'], row['OOS_tstat']),\n",
    "                fontsize=7, ha='left', va='bottom')\n",
    "\n",
    "ax1.set_xlabel('In-Sample t-statistic', fontsize=11)\n",
    "ax1.set_ylabel('Out-of-Sample t-statistic', fontsize=11)\n",
    "ax1.set_title('Factor Farming: In-Sample vs OOS t-statistics', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot: Bar chart of survival\n",
    "categories = ['Total\\nCandidates', 'Significant\\nIn-Sample', 'Significant\\nOut-of-Sample', 'Survive\\nOOS']\n",
    "counts = [n_total, n_sig_is, n_sig_oos, n_survives]\n",
    "bar_colors = ['steelblue', 'orange', 'coral', 'green']\n",
    "ax2.bar(categories, counts, color=bar_colors, edgecolor='black', alpha=0.8)\n",
    "for i, v in enumerate(counts):\n",
    "    ax2.text(i, v + 0.3, str(v), ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "ax2.set_title('Factor Farming: Attrition Funnel', fontweight='bold')\n",
    "ax2.set_ylabel('Number of Factors')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('factor_farming.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"(d) Discussion: Why Do Most In-Sample Factors Fail OOS?\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "Several reasons explain why most in-sample factors fail out-of-sample:\n",
    "\n",
    "1. DATA MINING / OVERFITTING: With hundreds of variables to test, some will\n",
    "   appear significant purely by chance (multiple testing problem). At a 5%\n",
    "   significance level, we expect ~1 in 20 random variables to appear significant.\n",
    "\n",
    "2. STRUCTURAL BREAKS: Market conditions, regulation, and investor behavior\n",
    "   change over time. A factor that worked in the past may no longer work because\n",
    "   the underlying economic mechanism has changed.\n",
    "\n",
    "3. ARBITRAGE AND CROWDING: Once a factor is discovered and widely traded,\n",
    "   the premium may shrink or disappear as capital flows in to exploit it.\n",
    "   This is especially true for factors published in academic literature.\n",
    "\n",
    "4. TRANSACTION COSTS: Even if a factor has statistical significance, the\n",
    "   premium may be too small to survive after trading costs, especially for\n",
    "   strategies involving small or illiquid stocks.\n",
    "\n",
    "5. SAMPLE-SPECIFIC PATTERNS: Some factors may capture patterns unique to\n",
    "   the training period (e.g., a bubble, a crisis) that don't repeat.\n",
    "\n",
    "This is a well-documented problem in finance. Harvey, Liu, and Zhu (2016)\n",
    "estimate that the t-statistic threshold should be raised to ~3.0 to account\n",
    "for the hundreds of factors that have been tested in the literature.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
